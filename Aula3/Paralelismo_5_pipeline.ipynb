{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paralelismo a Nível de Pipeline (Pipeline Parallelism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Pipeline Parallelism é uma técnica que permite treinar modelos de aprendizado profundo em várias GPUs, dividindo o modelo em várias seções (ou estágios) e processando diferentes mini-batches em cada estágio simultaneamente. Cada estágio do modelo é colocado em uma GPU diferente, e os tensores são passados de uma GPU para a próxima à medida que cada estágio é concluído.\n",
    "\n",
    "Vamos criar um exemplo simples usando o PyTorch para demonstrar o Pipeline Parallelism. Neste exemplo, vamos dividir um modelo de rede neural em dois estágios e executar cada estágio em uma GPU diferente.\n",
    "\n",
    "### Exemplo: Pipeline Parallelism com PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Verificar a disponibilidade de GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "assert num_gpus >= 2, \"Este exemplo requer pelo menos duas GPUs.\"\n",
    "\n",
    "# Modelo de rede neural dividido em dois estágios\n",
    "class SplitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SplitModel, self).__init__()\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Linear(10, 50),\n",
    "            nn.ReLU()\n",
    "        ).cuda(0)  # Primeiro estágio do modelo na GPU 0\n",
    "        \n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        ).cuda(1)  # Segundo estágio do modelo na GPU 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Processar na primeira GPU\n",
    "        x = self.stage1(x.cuda(0))\n",
    "        # Transferir para a segunda GPU e continuar o processamento\n",
    "        return self.stage2(x.cuda(1))\n",
    "\n",
    "# Criando dados sintéticos\n",
    "X = torch.rand(100, 10)\n",
    "\n",
    "# Treinamento com Pipeline Parallelism\n",
    "model = SplitModel()\n",
    "criterion = nn.MSELoss().cuda(1)  # Loss na GPU 1\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Simulando um DataLoader\n",
    "data_loader = [X[i:i+10] for i in range(0, len(X), 10)]\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x in data_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, torch.ones(len(x), 1).cuda(1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo:\n",
    "\n",
    "1. Criamos um modelo `SplitModel` que é dividido em dois estágios. O primeiro estágio é colocado na GPU 0 e o segundo estágio na GPU 1.\n",
    "2. Durante a passagem para a frente (`forward`), os dados são processados pelo primeiro estágio na GPU 0, depois são transferidos para a GPU 1 e processados pelo segundo estágio.\n",
    "3. O treinamento é realizado em mini-batches, simulando um pipeline onde cada estágio do modelo processa uma mini-batch diferente ao mesmo tempo.\n",
    "\n",
    "Este código assume que você tem pelo menos duas GPUs disponíveis. Se você tiver apenas uma GPU ou estiver executando em uma máquina sem GPUs, precisará ajustar o código de acordo.\n",
    "\n",
    "O Pipeline Parallelism é uma técnica avançada que pode ser útil ao treinar modelos grandes em grandes conjuntos de dados, especialmente quando combinada com outras técnicas de paralelismo, como paralelismo a nível de dados."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
